# üìÑ agent_classifier.py
# Ce module d√©termine dynamiquement quels agents doivent √™tre appel√©s via un prompt RAG
from langchain_groq import ChatGroq
# from langchain_ollama import OllamaLLM
import json
from model.agents.llm_loader import get_llm


llm = get_llm()

# üì• Chargement du prompt depuis le fichier
with open("model/prompts/classifier_prompt.txt", "r") as f:
    template = f.read()

def classifier_agent_node(question: str) -> list[str]:
    print("[DEBUG] Question envoy√©e au classifier :", question)

    prompt = template.format(question=question)
    response = llm.invoke(prompt)

    print("[DEBUG] R√©ponse brute du classifier :", response)
    try:
        # ‚úÖ Convertir la r√©ponse en liste Python
        agents = json.loads(response.content)
        print("[‚úÖ] Agents identifi√©s :", agents)
        return agents
    except json.JSONDecodeError:
        print("[‚ö†Ô∏è] Erreur : r√©ponse non JSON")
        return []
